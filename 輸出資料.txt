dropout_4 (Dropout)          (None, 6, 6, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 9216)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               4719104   
_________________________________________________________________
batch_normalization_8 (Batch (None, 512)               2048      
_________________________________________________________________
dropout_5 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_9 (Batch (None, 256)               1024      
_________________________________________________________________
dropout_6 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 1285      
=================================================================
Total params: 6,021,509
Trainable params: 6,018,117
Non-trainable params: 3,392


上面是模型概況
_________________________________________________________________
WARNING:tensorflow:From D:\Anaconda3\envs\AI108-2\lib\site-packages\keras\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From D:\Anaconda3\envs\AI108-2\lib\site-packages\tensorflow\python\ops\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Epoch 1/50
82/82 [==============================] - 23s 285ms/step - loss: 1.2433 - acc: 0.5904 - val_loss: 0.7990 - val_acc: 0.7959

Epoch 00001: val_acc improved from -inf to 0.79592, saving model to best_modelP.h5
Epoch 2/50
82/82 [==============================] - 8s 95ms/step - loss: 0.7252 - acc: 0.7652 - val_loss: 0.9330 - val_acc: 0.7823

Epoch 00002: val_acc did not improve from 0.79592
Epoch 3/50
82/82 [==============================] - 8s 96ms/step - loss: 0.6563 - acc: 0.7899 - val_loss: 0.3635 - val_acc: 0.8844

Epoch 00003: val_acc improved from 0.79592 to 0.88435, saving model to best_modelP.h5
Epoch 4/50
82/82 [==============================] - 8s 93ms/step - loss: 0.5716 - acc: 0.8147 - val_loss: 0.5911 - val_acc: 0.7959

Epoch 00004: val_acc did not improve from 0.88435
Epoch 5/50
82/82 [==============================] - 8s 94ms/step - loss: 0.5026 - acc: 0.8379 - val_loss: 0.2396 - val_acc: 0.9184

Epoch 00005: val_acc improved from 0.88435 to 0.91837, saving model to best_modelP.h5
Epoch 6/50
82/82 [==============================] - 8s 95ms/step - loss: 0.4523 - acc: 0.8565 - val_loss: 0.7141 - val_acc: 0.7551

Epoch 00006: val_acc did not improve from 0.91837
Epoch 7/50
82/82 [==============================] - 8s 94ms/step - loss: 0.4377 - acc: 0.8565 - val_loss: 0.4209 - val_acc: 0.8639

Epoch 00007: val_acc did not improve from 0.91837
Epoch 8/50
82/82 [==============================] - 8s 93ms/step - loss: 0.3992 - acc: 0.8741 - val_loss: 0.2698 - val_acc: 0.9048

Epoch 00008: val_acc did not improve from 0.91837
Epoch 9/50
82/82 [==============================] - 8s 95ms/step - loss: 0.4503 - acc: 0.8490 - val_loss: 0.3429 - val_acc: 0.8912

Epoch 00009: val_acc did not improve from 0.91837
Epoch 10/50
82/82 [==============================] - 8s 93ms/step - loss: 0.3809 - acc: 0.8747 - val_loss: 0.3712 - val_acc: 0.8844

Epoch 00010: val_acc did not improve from 0.91837
Epoch 11/50
82/82 [==============================] - 8s 94ms/step - loss: 0.3585 - acc: 0.8883 - val_loss: 0.3345 - val_acc: 0.9048

Epoch 00011: val_acc did not improve from 0.91837
Epoch 12/50
82/82 [==============================] - 8s 92ms/step - loss: 0.3926 - acc: 0.8762 - val_loss: 0.3241 - val_acc: 0.9048

Epoch 00012: val_acc did not improve from 0.91837
Epoch 13/50
82/82 [==============================] - 8s 93ms/step - loss: 0.3209 - acc: 0.8955 - val_loss: 0.2543 - val_acc: 0.9048

Epoch 00013: val_acc did not improve from 0.91837
Epoch 14/50
82/82 [==============================] - 15s 178ms/step - loss: 0.3427 - acc: 0.8907 - val_loss: 0.1537 - val_acc: 0.9524

Epoch 00014: val_acc improved from 0.91837 to 0.95238, saving model to best_modelP.h5
Epoch 15/50
82/82 [==============================] - 8s 97ms/step - loss: 0.2499 - acc: 0.9187 - val_loss: 0.3607 - val_acc: 0.8776

Epoch 00015: val_acc did not improve from 0.95238
Epoch 16/50
82/82 [==============================] - 8s 93ms/step - loss: 0.2838 - acc: 0.8961 - val_loss: 0.2808 - val_acc: 0.9116

Epoch 00016: val_acc did not improve from 0.95238
Epoch 17/50
82/82 [==============================] - 8s 93ms/step - loss: 0.2476 - acc: 0.9129 - val_loss: 0.1711 - val_acc: 0.9252

Epoch 00017: val_acc did not improve from 0.95238
Epoch 18/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2561 - acc: 0.9184 - val_loss: 0.2943 - val_acc: 0.8980

Epoch 00018: val_acc did not improve from 0.95238
Epoch 19/50
82/82 [==============================] - 8s 93ms/step - loss: 0.2512 - acc: 0.9106 - val_loss: 0.2888 - val_acc: 0.9048

Epoch 00019: val_acc did not improve from 0.95238
Epoch 20/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2504 - acc: 0.9153 - val_loss: 0.3045 - val_acc: 0.9048

Epoch 00020: val_acc did not improve from 0.95238
Epoch 21/50
82/82 [==============================] - 8s 94ms/step - loss: 0.2450 - acc: 0.9241 - val_loss: 0.2054 - val_acc: 0.9456

Epoch 00021: val_acc did not improve from 0.95238
Epoch 22/50
82/82 [==============================] - 8s 94ms/step - loss: 0.2340 - acc: 0.9226 - val_loss: 0.2415 - val_acc: 0.9184

Epoch 00022: val_acc did not improve from 0.95238
Epoch 23/50
82/82 [==============================] - 10s 121ms/step - loss: 0.2613 - acc: 0.9190 - val_loss: 0.3484 - val_acc: 0.9048

Epoch 00023: val_acc did not improve from 0.95238
Epoch 24/50
82/82 [==============================] - 13s 161ms/step - loss: 0.2670 - acc: 0.9056 - val_loss: 0.2565 - val_acc: 0.9388

Epoch 00024: val_acc did not improve from 0.95238
Epoch 25/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2118 - acc: 0.9264 - val_loss: 0.2645 - val_acc: 0.9184

Epoch 00025: val_acc did not improve from 0.95238
Epoch 26/50
82/82 [==============================] - 8s 93ms/step - loss: 0.2362 - acc: 0.9189 - val_loss: 0.3196 - val_acc: 0.9184

Epoch 00026: val_acc did not improve from 0.95238
Epoch 27/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2155 - acc: 0.9278 - val_loss: 0.2287 - val_acc: 0.9048

Epoch 00027: val_acc did not improve from 0.95238
Epoch 28/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2178 - acc: 0.9274 - val_loss: 0.1896 - val_acc: 0.9320

Epoch 00028: val_acc did not improve from 0.95238
Epoch 29/50
82/82 [==============================] - 7s 91ms/step - loss: 0.2100 - acc: 0.9274 - val_loss: 0.1812 - val_acc: 0.9252

Epoch 00029: val_acc did not improve from 0.95238
Epoch 30/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1652 - acc: 0.9431 - val_loss: 0.1671 - val_acc: 0.9456

Epoch 00030: val_acc did not improve from 0.95238
Epoch 31/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1793 - acc: 0.9326 - val_loss: 0.2510 - val_acc: 0.9184

Epoch 00031: val_acc did not improve from 0.95238
Epoch 32/50
82/82 [==============================] - 8s 93ms/step - loss: 0.1863 - acc: 0.9386 - val_loss: 0.3152 - val_acc: 0.8707

Epoch 00032: val_acc did not improve from 0.95238
Epoch 33/50
82/82 [==============================] - 8s 91ms/step - loss: 0.1980 - acc: 0.9281 - val_loss: 0.4052 - val_acc: 0.8776

Epoch 00033: val_acc did not improve from 0.95238
Epoch 34/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2064 - acc: 0.9277 - val_loss: 0.5490 - val_acc: 0.8503

Epoch 00034: val_acc did not improve from 0.95238
Epoch 35/50
82/82 [==============================] - 8s 92ms/step - loss: 0.2069 - acc: 0.9296 - val_loss: 0.3037 - val_acc: 0.9116

Epoch 00035: val_acc did not improve from 0.95238
Epoch 36/50
82/82 [==============================] - 14s 169ms/step - loss: 0.1919 - acc: 0.9366 - val_loss: 0.2045 - val_acc: 0.9184

Epoch 00036: val_acc did not improve from 0.95238
Epoch 37/50
82/82 [==============================] - 9s 108ms/step - loss: 0.1724 - acc: 0.9462 - val_loss: 0.1582 - val_acc: 0.9524

Epoch 00037: val_acc did not improve from 0.95238
Epoch 38/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1682 - acc: 0.9431 - val_loss: 0.1767 - val_acc: 0.9320

Epoch 00038: val_acc did not improve from 0.95238
Epoch 39/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1449 - acc: 0.9535 - val_loss: 0.2764 - val_acc: 0.9184

Epoch 00039: val_acc did not improve from 0.95238
Epoch 40/50
82/82 [==============================] - 8s 93ms/step - loss: 0.1299 - acc: 0.9565 - val_loss: 0.1539 - val_acc: 0.9320

Epoch 00040: val_acc did not improve from 0.95238
Epoch 41/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1740 - acc: 0.9378 - val_loss: 0.3433 - val_acc: 0.8776

Epoch 00041: val_acc did not improve from 0.95238
Epoch 42/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1658 - acc: 0.9426 - val_loss: 0.6213 - val_acc: 0.8095

Epoch 00042: val_acc did not improve from 0.95238
Epoch 43/50
82/82 [==============================] - 8s 93ms/step - loss: 0.1617 - acc: 0.9462 - val_loss: 0.2242 - val_acc: 0.9252

Epoch 00043: val_acc did not improve from 0.95238
Epoch 44/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1472 - acc: 0.9476 - val_loss: 0.2273 - val_acc: 0.9116

Epoch 00044: val_acc did not improve from 0.95238
Epoch 45/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1528 - acc: 0.9481 - val_loss: 0.1924 - val_acc: 0.9184

Epoch 00045: val_acc did not improve from 0.95238
Epoch 46/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1572 - acc: 0.9481 - val_loss: 0.2116 - val_acc: 0.9388

Epoch 00046: val_acc did not improve from 0.95238
Epoch 47/50
82/82 [==============================] - 15s 185ms/step - loss: 0.1249 - acc: 0.9576 - val_loss: 0.1527 - val_acc: 0.9524

Epoch 00047: val_acc did not improve from 0.95238
Epoch 48/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1293 - acc: 0.9580 - val_loss: 0.2002 - val_acc: 0.9252

Epoch 00048: val_acc did not improve from 0.95238
Epoch 49/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1399 - acc: 0.9511 - val_loss: 0.1733 - val_acc: 0.9456

Epoch 00049: val_acc did not improve from 0.95238
Epoch 50/50
82/82 [==============================] - 8s 92ms/step - loss: 0.1356 - acc: 0.9543 - val_loss: 0.1510 - val_acc: 0.9592

Epoch 00050: val_acc improved from 0.95238 to 0.95918, saving model to best_modelP.h5

runfile('D:/AIpython/pokemon.py', wdir='D:/AIpython')
D:\AIpython\dataset1\dataset\Mewtwo\ed9eb0e7d3494c6992e06196f5b7cc05.svg [ERROR] can't read the file
DONE
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_8 (Conv2D)            (None, 96, 96, 32)        896       
_________________________________________________________________
batch_normalization_10 (Batc (None, 96, 96, 32)        128       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 48, 48, 32)        0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 48, 48, 32)        0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 48, 48, 64)        18496     
_________________________________________________________________
batch_normalization_11 (Batc (None, 48, 48, 64)        256       
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 48, 48, 64)        36928     
_________________________________________________________________
batch_normalization_12 (Batc (None, 48, 48, 64)        256       
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 24, 24, 64)        0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 24, 24, 64)        0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 24, 24, 128)       73856     
_________________________________________________________________
batch_normalization_13 (Batc (None, 24, 24, 128)       512       
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 24, 24, 128)       147584    
_________________________________________________________________
batch_normalization_14 (Batc (None, 24, 24, 128)       512       
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 12, 12, 128)       0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 12, 12, 128)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 12, 12, 256)       295168    
_________________________________________________________________
batch_normalization_15 (Batc (None, 12, 12, 256)       1024      
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 12, 12, 256)       590080    
_________________________________________________________________
batch_normalization_16 (Batc (None, 12, 12, 256)       1024      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 6, 6, 256)         0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 6, 6, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 9216)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 512)               4719104   
_________________________________________________________________
batch_normalization_17 (Batc (None, 512)               2048      
_________________________________________________________________
dropout_11 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_18 (Batc (None, 256)               1024      
_________________________________________________________________
dropout_12 (Dropout)         (None, 256)               0         
_________________________________________________________________
dense_6 (Dense)              (None, 5)                 1285      
=================================================================
Total params: 6,021,509
Trainable params: 6,018,117
Non-trainable params: 3,392
_________________________________________________________________
Epoch 1/50
264/264 [==============================] - 27s 102ms/step - loss: 0.8546 - acc: 0.7256 - val_loss: 0.3601 - val_acc: 0.8980

Epoch 00001: val_acc improved from -inf to 0.89796, saving model to best_modelP.h5
Epoch 2/50
264/264 [==============================] - 24s 93ms/step - loss: 0.4676 - acc: 0.8451 - val_loss: 0.3476 - val_acc: 0.8980

Epoch 00002: val_acc improved from 0.89796 to 0.89796, saving model to best_modelP.h5
Epoch 3/50
264/264 [==============================] - 24s 92ms/step - loss: 0.3600 - acc: 0.8821 - val_loss: 0.1876 - val_acc: 0.9320

Epoch 00003: val_acc improved from 0.89796 to 0.93197, saving model to best_modelP.h5
Epoch 4/50
264/264 [==============================] - 24s 91ms/step - loss: 0.3036 - acc: 0.8982 - val_loss: 0.5028 - val_acc: 0.8571

Epoch 00004: val_acc did not improve from 0.93197
Epoch 5/50
264/264 [==============================] - 24s 92ms/step - loss: 0.2746 - acc: 0.9100 - val_loss: 0.2094 - val_acc: 0.9252

Epoch 00005: val_acc did not improve from 0.93197
Epoch 6/50
264/264 [==============================] - 24s 92ms/step - loss: 0.2392 - acc: 0.9180 - val_loss: 0.2247 - val_acc: 0.9388

Epoch 00006: val_acc improved from 0.93197 to 0.93878, saving model to best_modelP.h5
Epoch 7/50
264/264 [==============================] - 25s 93ms/step - loss: 0.2438 - acc: 0.9186 - val_loss: 0.1840 - val_acc: 0.9320

Epoch 00007: val_acc did not improve from 0.93878
Epoch 8/50
264/264 [==============================] - 25s 95ms/step - loss: 0.2074 - acc: 0.9295 - val_loss: 0.3214 - val_acc: 0.9116

Epoch 00008: val_acc did not improve from 0.93878
Epoch 9/50
264/264 [==============================] - 24s 93ms/step - loss: 0.1966 - acc: 0.9335 - val_loss: 0.2321 - val_acc: 0.9252

Epoch 00009: val_acc did not improve from 0.93878
Epoch 10/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1842 - acc: 0.9370 - val_loss: 0.1402 - val_acc: 0.9456

Epoch 00010: val_acc improved from 0.93878 to 0.94558, saving model to best_modelP.h5
Epoch 11/50
264/264 [==============================] - 24s 91ms/step - loss: 0.2019 - acc: 0.9322 - val_loss: 0.2424 - val_acc: 0.9388

Epoch 00011: val_acc did not improve from 0.94558
Epoch 12/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1802 - acc: 0.9405 - val_loss: 0.2535 - val_acc: 0.9252

Epoch 00012: val_acc did not improve from 0.94558
Epoch 13/50
264/264 [==============================] - 25s 94ms/step - loss: 0.1607 - acc: 0.9467 - val_loss: 0.1549 - val_acc: 0.9524

Epoch 00013: val_acc improved from 0.94558 to 0.95238, saving model to best_modelP.h5
Epoch 14/50
264/264 [==============================] - 28s 105ms/step - loss: 0.1457 - acc: 0.9557 - val_loss: 0.1743 - val_acc: 0.9456

Epoch 00014: val_acc did not improve from 0.95238
Epoch 15/50
264/264 [==============================] - 25s 94ms/step - loss: 0.1364 - acc: 0.9527 - val_loss: 0.2302 - val_acc: 0.9252

Epoch 00015: val_acc did not improve from 0.95238
Epoch 16/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1255 - acc: 0.9577 - val_loss: 0.2298 - val_acc: 0.9456

Epoch 00016: val_acc did not improve from 0.95238
Epoch 17/50
264/264 [==============================] - 25s 93ms/step - loss: 0.1368 - acc: 0.9541 - val_loss: 0.1896 - val_acc: 0.9388

Epoch 00017: val_acc did not improve from 0.95238
Epoch 18/50
264/264 [==============================] - 25s 93ms/step - loss: 0.1174 - acc: 0.9596 - val_loss: 0.2063 - val_acc: 0.9252

Epoch 00018: val_acc did not improve from 0.95238
Epoch 19/50
264/264 [==============================] - 24s 93ms/step - loss: 0.1336 - acc: 0.9557 - val_loss: 0.2227 - val_acc: 0.9320

Epoch 00019: val_acc did not improve from 0.95238
Epoch 20/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1151 - acc: 0.9598 - val_loss: 0.2064 - val_acc: 0.9252

Epoch 00020: val_acc did not improve from 0.95238
Epoch 21/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1116 - acc: 0.9637 - val_loss: 0.1375 - val_acc: 0.9592

Epoch 00021: val_acc improved from 0.95238 to 0.95918, saving model to best_modelP.h5
Epoch 22/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1087 - acc: 0.9634 - val_loss: 0.3627 - val_acc: 0.8912

Epoch 00022: val_acc did not improve from 0.95918
Epoch 23/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1214 - acc: 0.9591 - val_loss: 0.3539 - val_acc: 0.9116

Epoch 00023: val_acc did not improve from 0.95918
Epoch 24/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0955 - acc: 0.9700 - val_loss: 0.1181 - val_acc: 0.9592

Epoch 00024: val_acc improved from 0.95918 to 0.95918, saving model to best_modelP.h5
Epoch 25/50
264/264 [==============================] - 24s 91ms/step - loss: 0.1203 - acc: 0.9629 - val_loss: 0.2280 - val_acc: 0.9320

Epoch 00025: val_acc did not improve from 0.95918
Epoch 26/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0944 - acc: 0.9673 - val_loss: 0.1877 - val_acc: 0.9456

Epoch 00026: val_acc did not improve from 0.95918
Epoch 27/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1004 - acc: 0.9678 - val_loss: 0.2362 - val_acc: 0.9524

Epoch 00027: val_acc did not improve from 0.95918
Epoch 28/50
264/264 [==============================] - 24s 93ms/step - loss: 0.0882 - acc: 0.9691 - val_loss: 0.1929 - val_acc: 0.9388

Epoch 00028: val_acc did not improve from 0.95918
Epoch 29/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0746 - acc: 0.9750 - val_loss: 0.2132 - val_acc: 0.9388

Epoch 00029: val_acc did not improve from 0.95918
Epoch 30/50
264/264 [==============================] - 24s 92ms/step - loss: 0.1032 - acc: 0.9650 - val_loss: 0.1417 - val_acc: 0.9456

Epoch 00030: val_acc did not improve from 0.95918
Epoch 31/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0818 - acc: 0.9707 - val_loss: 1.0849 - val_acc: 0.7687

Epoch 00031: val_acc did not improve from 0.95918
Epoch 32/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0786 - acc: 0.9744 - val_loss: 0.1417 - val_acc: 0.9592

Epoch 00032: val_acc improved from 0.95918 to 0.95918, saving model to best_modelP.h5
Epoch 33/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0790 - acc: 0.9727 - val_loss: 0.1938 - val_acc: 0.9184

Epoch 00033: val_acc did not improve from 0.95918
Epoch 34/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0661 - acc: 0.9766 - val_loss: 0.1673 - val_acc: 0.9456

Epoch 00034: val_acc did not improve from 0.95918
Epoch 35/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0750 - acc: 0.9757 - val_loss: 0.1652 - val_acc: 0.9524

Epoch 00035: val_acc did not improve from 0.95918
Epoch 36/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0694 - acc: 0.9755 - val_loss: 0.2629 - val_acc: 0.9116

Epoch 00036: val_acc did not improve from 0.95918
Epoch 37/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0780 - acc: 0.9725 - val_loss: 0.1625 - val_acc: 0.9456

Epoch 00037: val_acc did not improve from 0.95918
Epoch 38/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0779 - acc: 0.9734 - val_loss: 0.1842 - val_acc: 0.9524

Epoch 00038: val_acc did not improve from 0.95918
Epoch 39/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0567 - acc: 0.9795 - val_loss: 0.2090 - val_acc: 0.9456

Epoch 00039: val_acc did not improve from 0.95918
Epoch 40/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0600 - acc: 0.9796 - val_loss: 0.1963 - val_acc: 0.9592

Epoch 00040: val_acc did not improve from 0.95918
Epoch 41/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0567 - acc: 0.9803 - val_loss: 0.1968 - val_acc: 0.9456

Epoch 00041: val_acc did not improve from 0.95918
Epoch 42/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0773 - acc: 0.9749 - val_loss: 0.1721 - val_acc: 0.9388

Epoch 00042: val_acc did not improve from 0.95918
Epoch 43/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0585 - acc: 0.9776 - val_loss: 0.0846 - val_acc: 0.9728

Epoch 00043: val_acc improved from 0.95918 to 0.97279, saving model to best_modelP.h5
Epoch 44/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0646 - acc: 0.9782 - val_loss: 0.1503 - val_acc: 0.9456

Epoch 00044: val_acc did not improve from 0.97279
Epoch 45/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0547 - acc: 0.9795 - val_loss: 0.1376 - val_acc: 0.9456

Epoch 00045: val_acc did not improve from 0.97279
Epoch 46/50
264/264 [==============================] - 24s 92ms/step - loss: 0.0671 - acc: 0.9765 - val_loss: 0.1547 - val_acc: 0.9388

Epoch 00046: val_acc did not improve from 0.97279
Epoch 47/50
264/264 [==============================] - 25s 93ms/step - loss: 0.0509 - acc: 0.9819 - val_loss: 0.2323 - val_acc: 0.9252

Epoch 00047: val_acc did not improve from 0.97279
Epoch 48/50
264/264 [==============================] - 25s 93ms/step - loss: 0.0463 - acc: 0.9830 - val_loss: 0.0924 - val_acc: 0.9728

Epoch 00048: val_acc did not improve from 0.97279
Epoch 49/50
264/264 [==============================] - 25s 93ms/step - loss: 0.0596 - acc: 0.9788 - val_loss: 0.3012 - val_acc: 0.9116

Epoch 00049: val_acc did not improve from 0.97279
Epoch 50/50
264/264 [==============================] - 25s 93ms/step - loss: 0.0487 - acc: 0.9825 - val_loss: 0.1565 - val_acc: 0.9524

Epoch 00050: val_acc did not improve from 0.97279